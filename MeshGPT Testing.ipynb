{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:12.944690Z","iopub.status.busy":"2023-12-19T01:39:12.944345Z","iopub.status.idle":"2023-12-19T01:39:38.152713Z","shell.execute_reply":"2023-12-19T01:39:38.151433Z","shell.execute_reply.started":"2023-12-19T01:39:12.944662Z"},"trusted":true},"outputs":[],"source":["!pip install -q git+https://github.com/MarcusLoppe/meshgpt-pytorch.git trimesh"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:38.155749Z","iopub.status.busy":"2023-12-19T01:39:38.155103Z","iopub.status.idle":"2023-12-19T01:39:44.048426Z","shell.execute_reply":"2023-12-19T01:39:44.047605Z","shell.execute_reply.started":"2023-12-19T01:39:38.155692Z"},"trusted":true},"outputs":[],"source":["import torch\n","import trimesh\n","import numpy as np\n","import os\n","import csv \n","import json\n","import math \n","from collections import OrderedDict\n","\n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer\n",")\n","\n","def get_3d_data(file_path): \n","    mesh = trimesh.load(file_path, force='mesh')\n","    \n","    # Extract vertices and faces\n","    vertices = mesh.vertices.tolist()\n","    faces = mesh.faces.tolist()\n","    centered_vertices = vertices - np.mean(vertices, axis=0)\n"," \n","    max_abs = np.max(np.abs(centered_vertices))\n","    vertices = centered_vertices / (max_abs / 0.95)  \n","      \n","      \n","    def sort_vertices(vertex): # Sort by Y , X, Z.  Y is vertical\n","        return vertex[1], vertex[0], vertex[2]   \n"," \n","    seen = OrderedDict()\n","    for point in vertices: \n","      key = tuple(point)\n","      if key not in seen:\n","        seen[key] = point\n","    unique_vertices =  list(seen.values()) \n","    sorted_vertices = sorted(unique_vertices, key=sort_vertices)\n","     \n","    vertices_as_tuples = [tuple(v) for v in vertices]\n","    sorted_vertices_as_tuples = [tuple(v) for v in sorted_vertices]\n","\n","    vertex_map = {old_index: new_index for old_index, vertex_tuple in enumerate(vertices_as_tuples) for new_index, sorted_vertex_tuple in enumerate(sorted_vertices_as_tuples) if vertex_tuple == sorted_vertex_tuple}\n"," \n","\n","    reindexed_faces = [[vertex_map[face[0]], vertex_map[face[1]], vertex_map[face[2]]] for face in faces] \n","    return np.array(sorted_vertices), np.array(reindexed_faces)\n","\n","def augment_mesh_scalar(vertices, scale_factor):\n","    # Apply a scalar factor to XYZ coordinates\n","    transformed_vertices = vertices * scale_factor\n","    return transformed_vertices\n","\n","def generate_scale_factors(num_examples, lower_limit=0.75, upper_limit=1.25): \n","    scale_factors = np.random.uniform(lower_limit, upper_limit, size=num_examples)\n","    return scale_factors\n","\n","def jitter_mesh(vertices, jitter_factor=0.01): \n","    offsets = np.random.uniform(-jitter_factor, jitter_factor, size=vertices.shape)\n"," \n","    jittered_vertices = vertices + offsets \n","    return jittered_vertices \n","\n","def augment_mesh(vertices, scale_factor):\n","    #vertices = jitter_mesh(vertices)\n","    transformed_vertices = vertices * scale_factor\n","    \n","    return transformed_vertices\n"," \n","\n","def load_models(directory, num_examples, variations):\n","    obj_datas = []  \n","    \n","    print(f\"num_examples: {num_examples}\")\n","    for filename in os.listdir(directory):  \n","        if (filename.endswith(\".obj\") or  filename.endswith(\".glb\") or  filename.endswith(\".off\")):\n","            file_path = os.path.join(directory, filename)\n","\n","            scale_factors = generate_scale_factors(variations, 0.7, 0.9) \n","            vertices, faces = get_3d_data(file_path) \n","\n","            for scale_factor in scale_factors: \n","                aug_vertices = augment_mesh(vertices.copy(), scale_factor) \n","                \n","                for _ in range(num_examples):\n","                    obj_data = {\"vertices\": aug_vertices.tolist(), \"faces\":  faces.tolist(), \"texts\": filename[:-4]}\n","                    obj_datas.append(obj_data)   \n","    return obj_datas\n","  \n","\n","\n","  \n","def load_json(file,num_examples):\n","    obj_datas = []\n","    with open(file, \"r\") as json_file:\n","        loaded_data = json.load(json_file) \n","        for item in loaded_data:\n","            for _ in range(num_examples): \n","                obj_data = {\"vertices\": torch.tensor(item[\"vertices\"], dtype=torch.float).to(\"cuda\"), \"faces\":  torch.tensor(item[\"faces\"], dtype=torch.long).to(\"cuda\"),\"texts\": item[\"texts\"] } \n","                obj_datas.append(obj_data)\n","    return obj_datas\n","                        \n","         "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:44.050017Z","iopub.status.busy":"2023-12-19T01:39:44.049685Z","iopub.status.idle":"2023-12-19T01:39:44.063671Z","shell.execute_reply":"2023-12-19T01:39:44.062641Z","shell.execute_reply.started":"2023-12-19T01:39:44.049992Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import Tensor, tensor\n","from torch.utils.data import Dataset, DataLoader \n","from tqdm import tqdm\n","import numpy as np \n","import gc\n","from torch.nn.utils.rnn import pad_sequence\n","from meshgpt_pytorch.data import ( \n","    derive_face_edges_from_faces\n",") \n"," \n","class MeshDataset(Dataset): \n","    \n","    def __init__(self, data): \n","        self.data = data\n","        print(f\"Got {len(data)} data\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx): \n","        data = self.data[idx] \n","        return data  \n","    \n","    def save(self, path):\n","        np.savez_compressed(path, *self.data)\n","\n","    \n","    @classmethod\n","    def load(cls, path): \n","        loaded_data = np.load(path, allow_pickle=True)\n"," \n","        data = []\n","        for i in range(len(loaded_data.files)):\n","            data_item = {}\n","            for key in loaded_data[f\"arr_{i}\"].item():\n","                data_item[key] = loaded_data[f\"arr_{i}\"].item()[key]\n","            data.append(data_item)\n","\n","        return cls(data)\n","    \n","    def embed_texts(self,transformer): \n","        unique_texts = set(item['texts'] for item in self.data)\n"," \n","        text_embeddings = transformer.embed_texts(list(unique_texts))\n","        print(f\"Got text_embeddings: {len(text_embeddings)}\") \n","        text_embedding_dict = dict(zip(unique_texts, text_embeddings))\n"," \n","        for item in self.data:\n","            text_value = item['texts']\n","            item['text_embeds'] = text_embedding_dict.get(text_value, None)\n","            del item['texts']\n","            \n","    def generate_face_edges(self):\n","        n = 0\n","        for i in range(0, len(self.data)):  \n","            item = self.data[i]\n","            item['face_edges'] =  derive_face_edges_from_faces(item['faces'])\n","            n += 1  \n","        print(f\"done {n}/{len(self.data)}\")\n","\n","    def generate_codes(self, autoencoder : MeshAutoencoder):\n","        n = 0\n","        for i in range(0, len(self.data)):  \n","            item = self.data[i]\n","             \n","            codes = autoencoder.tokenize(\n","                vertices = item['vertices'],\n","                faces = item['faces'],\n","                face_edges = item['face_edges']\n","            ) \n","            item['codes'] = codes \n","            n += 1  \n","\n","        print(f\"[generate_codes] done {n}/{len(self.data)}\") \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:44.066146Z","iopub.status.busy":"2023-12-19T01:39:44.065812Z","iopub.status.idle":"2023-12-19T01:39:52.313349Z","shell.execute_reply":"2023-12-19T01:39:52.312381Z","shell.execute_reply.started":"2023-12-19T01:39:44.066116Z"},"trusted":true},"outputs":[],"source":["import json\n","#tables = load_models(r\" filtered\",5,5)  \n","#with open(\"data.json\", \"w\") as json_file:\n","#    json.dump(tables, json_file) \n","\n","tables = load_json(\"/kaggle/input/shapenet/data.json\",2)\n","dataset = MeshDataset(tables) \n","dataset.generate_face_edges()\n","dataset.data[0].keys()\n","\n","desired_order = ['vertices', 'faces', 'face_edges', 'texts']\n","\n","dataset.data = [\n","    {key: d[key] for key in desired_order} for d in dataset.data\n","]\n","\n","unique_values = set(item[\"texts\"] for item in dataset.data)\n","\n","print(len(unique_values))  \n","print(unique_values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["autoencoder = MeshAutoencoder( \n","    num_discrete_coors = 128  , \n",") \n","total_params = sum(p.numel() for p in autoencoder.encoders.parameters())\n","print(f\"encoders Total parameters: {total_params}\")\n","total_params = sum(p.numel() for p in autoencoder.decoders.parameters())\n","print(f\"decoders Total parameters: {total_params}\")  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:44:00.715656Z","iopub.status.busy":"2023-12-19T01:44:00.714727Z","iopub.status.idle":"2023-12-19T12:00:40.840982Z","shell.execute_reply":"2023-12-19T12:00:40.840110Z","shell.execute_reply.started":"2023-12-19T01:44:00.715620Z"},"trusted":true},"outputs":[],"source":["total_params = sum(p.numel() for p in autoencoder.encoders.parameters())\n","print(f\"Total parameters: {total_params}\")\n","print(autoencoder.encoders)\n","\n","autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder,learning_rate = 1e-3, \n","                                             warmup_steps = 10,\n","                                             dataset = dataset,   \n","                                             num_train_steps=100,\n","                                             batch_size=16,\n","                                             grad_accum_every=1)\n","\n","loss = autoencoder_trainer.train(40,stop_at_loss = 0.25)   \n","autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder,learning_rate = 1e-4, \n","                                             warmup_steps = 10,\n","                                             dataset = dataset,\n","                                             checkpoint_every_epoch = 20,  \n","                                             num_train_steps=100,\n","                                             batch_size=16,\n","                                             grad_accum_every=1)\n","\n","loss = autoencoder_trainer.train(180,stop_at_loss = 0.25)   \n","autoencoder_trainer.save(f'./mesh-encoder_2_loss_{loss:.3f}.pt') "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d) \n","max_seq =  max_length * 6  \n","print(max_length)\n","print(max_seq)\n","transformer = MeshTransformer(\n","    autoencoder,\n","    dim = 512,\n","    max_seq_len = max_seq,\n","    coarse_pre_gateloop_depth = 6,\n","    fine_pre_gateloop_depth= 4, \n","    condition_on_text = True\n",")\n","total_params = sum(p.numel() for p in transformer.parameters())\n","print(f\"Total parameters: {total_params}\") "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.embed_texts(transformer)\n","dataset.generate_codes(autoencoder,1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" \n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100,   dataset = dataset,\n","                                 learning_rate = 1e-1, batch_size=2)\n","trainer.train(80,stop_at_loss = 0.00009)   \n","\n"," \n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100,  dataset = dataset,\n","                                 learning_rate = 1e-2, batch_size=2)\n","trainer.train(80,stop_at_loss = 0.00009)    \n","\n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100,  dataset = dataset,\n","                                 learning_rate = 1e-4, batch_size=2)\n","trainer.train(80,stop_at_loss = 0.00009)   \n","\n","trainer.save(f'./mesh-transformer_2_{loss:.3f}.pt')    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["unique_values = set(item[\"texts\"] for item in dataset.data)\n","print(len(unique_values))  \n","coords = []\n","for text in unique_values: \n","    print(f\"doing {text}\")\n","    faces_coordinates = transformer.generate(texts = [text]) \n","    coords.append(faces_coordinates)\n","    tensor_data = faces_coordinates[0].cpu()\n","    \n","    numpy_data = tensor_data.numpy().reshape(-1, 3)\n","    \n","    obj_file_content = \"\"\n","    \n","    for vertex in numpy_data:\n","        obj_file_content += f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\"\n","\n","    for i in range(1, len(numpy_data), 3):\n","        obj_file_content += f\"f {i} {i + 1} {i + 2}\\n\"\n","\n","    # Save to a file\n","    obj_file_path = f'./tests/3d_output_{text}.obj'\n","    with open(obj_file_path, \"w\") as file:\n","        file.write(obj_file_content)\n","\n","    print(obj_file_path) \n","    \n","    \n","all_vertices = []\n","all_faces = []\n","vertex_offset = 0\n"," \n","translation_distance = 0.3  \n","\n","for r, faces_coordinates in enumerate(coords): \n","    tensor_data = faces_coordinates[0].cpu()\n","\n","    numpy_data = tensor_data.numpy().reshape(-1, 3)\n","\n","    # Translate the model to avoid overlapping\n","    numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)  # Adjust X coordinate\n","\n","    # Accumulate vertices\n","    for vertex in numpy_data:\n","        all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n","\n","    # Accumulate faces with adjusted indices\n","    for i in range(1, len(numpy_data), 3):\n","        all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n","\n","    # Update the vertex offset for the next model\n","    vertex_offset += len(numpy_data)\n","\n","# Combine vertices and faces\n","obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n","\n","# Save to a single file\n","obj_file_path = f\"./tests/3d_models_all.obj\"\n","with open(obj_file_path, \"w\") as file:\n","    file.write(obj_file_content)\n","\n","print(obj_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","coords_all = []\n","for text in set(item[\"texts\"] for item in dataset.data): \n","    print(f\"Doing {text}\")\n","    coords = []\n","    for r in np.arange(0, 1.0, 0.1):\n","        faces_coordinates = transformer.generate(temperature=r, texts = [text]) \n","        coords.append(faces_coordinates)\n","    coords_all.append(coords)\n","    \n","    all_vertices = []\n","    all_faces = []\n","    vertex_offset = 0\n","\n","    # Translation distance for each model\n","    translation_distance = 0.3  # Adjust as needed\n","\n","    for r, faces_coordinates in enumerate(coords): \n","        tensor_data = faces_coordinates[0].cpu()\n","\n","        numpy_data = tensor_data.numpy().reshape(-1, 3)\n","\n","        # Translate the model to avoid overlapping\n","        numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)  # Adjust X coordinate\n","\n","        # Accumulate vertices\n","        for vertex in numpy_data:\n","            all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n","\n","        # Accumulate faces with adjusted indices\n","        for i in range(1, len(numpy_data), 3):\n","            all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n","\n","        # Update the vertex offset for the next model\n","        vertex_offset += len(numpy_data)\n","\n","    # Combine vertices and faces\n","    obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n","\n","    # Save to a single file\n","    obj_file_path = f\"./results/3d_models_{text}_temps.obj\"\n","    with open(obj_file_path, \"w\") as file:\n","        file.write(obj_file_content)\n","\n","    print(obj_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def loadModels():\n","    autoencoder = MeshAutoencoder(\n","        dim = 576,\n","        encoder_depth = 6,\n","        decoder_depth = 6,\n","        num_discrete_coors = 128  ,\n","        local_attn_depth =0, \n","        \n","    )\n","    autoencoder_trainer = MeshAutoencoderTrainer(model = autoencoder,\n","                                    learning_rate = 1e-1, \n","                                                checkpoint_every_epoch= 5,\n","                                                warmup_steps = 10,\n","                                                dataset = dataset,  \n","                                                num_train_steps=100,\n","                                                batch_size=2,\n","                                                grad_accum_every=1)\n","\n","    autoencoder_trainer.load(r\"mesh-encoder_last.pt\")\n","    encoder = autoencoder_trainer.model\n","    max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d) \n","    max_seq =  max_length * 6  \n","    \n","    transformer = MeshTransformer(\n","        autoencoder,\n","        dim = 768,\n","        max_seq_len = max_seq,\n","        condition_on_text = True)\n","     \n","    trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100, checkpoint_folder = r\"F:\\MachineLearning\\Mesh\\MeshGPT\\checkpoints\" , dataset = dataset,\n","                                    learning_rate = 1e-3, batch_size=2) \n","    trainer.load(r\"mesh-transformer.pt\")\n","    transformer = trainer.model\n","    return transformer, encoder\n","\n","#transformer, autoencoder =  loadModels() "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4189032,"sourceId":7234116,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
